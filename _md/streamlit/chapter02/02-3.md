---
chapter: Streamlit 요소 알아보기
title: 미디어 요소 입출력
date: 2025-03-24
---

이미지, 동영상, 오디오 파일을 앱에 바로 임베드할 수 있습니다. 이를 통해 다양한 미디어 콘텐츠를 별도의 프로그램 없이도 손쉽게 확인할 수 있습니다.

또한, 본 강의 실습에 필요한 모든 자료는 아래 ZIP 파일로 제공되며, 아래 링크에서 실습 자료 전체를 일괄 다운로드하실 수 있습니다.

::a[실습 자료]{class='btn-link' href="/images/streamlit/chapter02/part03/실습자료.zip" download}

<br>
<br>

# **st.image**

`st.image`는 이미지 콘텐츠를 출력합니다.

```python
st.image(image, caption=None, width=None, use_column_width=None,
         clamp=False, channels="RGB", output_format="auto", *, use_container_width=False)
```

<br>

**매개변수**

- `image`(numpy.ndarray, BytesIO, str, Path, list of these) : 표시할 이미지로 다양한 형식의 이미지 파일 또는 호스팅된 이미지의 URL을 나타냅니다. 필요에 따라 넘쳐나는 이미지를 추가 행 또는 리스트로 표시합니다.
  - 로컬 이미지 파일의 경로는 문자열 또는 Path 객체(이미지를 가져올 URL)입니다. 경로는 작업 디렉터리(Streamlit을 실행하는 위치)에 대한 절대 또는 상대 경로입니다.
  - 이미지를 정의하는 Byte 배열입니다. (w,h) 또는 (w,h,1)의 흑백 이미지, (w,h,3)의 컬러 이미지 또는 (w,h,4)의 RGBA 이미지(w와 h는 각각 이미지 폭과 높이) 여야 합니다.
    - (w, h) 또는 (w, h, 1) 모양의 단색 이미지
    - (w, h, 3) 모양의 컬러 이미지
    - (w, h, 4) 모양의 RGBA 이미지
  - SVG(확장 가능한 벡터 그래픽) XML 문자열
    ex) `<svg xmlns=...</svg>`
- `caption`(str, list of str) : 이미지 캡션을 나타냅니다. 여러 이미지를 표시하는 경우 캡션 목록(각 이미지 마다 하나의 캡션) 형태여야 합니다. 캡션에는 마크다운을 사용할 수 있으며, None(기본값)이면 캡션이 표시되지 않습니다.
- `width`(int, None) : 이미지 너비를 나타내며 None(기본값)인 경우 이미지의 기본 너비를 부모 컨테이너 너비까지 콘텐츠에 맞게 설정합니다. 기본 너비가 없는 SVG 이미지를 사용하는 경우 너비를 선언하거나 use_container_width=True를 사용해야 합니다.
- `clamp`(bool) : 이미지 픽셀 값을 유효한 범위(채널당 0~255)로 제한할지 여부입니다. Byte 배열 이미지에서만 사용되며 이미지 URL 및 파일을 넣을 때는 적용되지 않습니다. False(기본값)일 때는 이미지의 값이 범위를 벗어난 값이 있는 경우 RuntimeError가 발생합니다.
- `channels`(“RGB”, “BGR”) : 이미지가 nd.array인 경우, 색상 정보를 표현하는데 사용되는 형식을 나타냅니다. 다른 이미지에는 적용되지 않습니다.
  - "RGB"(기본값) : image[:, :, 0]은 빨간색 채널, image[:, :, 1]은 녹색 채널, image[:, :, 2]는 파란색 채널이 됩니다.
  - "BGR" : OpenCV와 같은 라이브러리에서 가져온 이미지입니다.
- `output_format`(“JPEG”, “PNG”, “auto”) : 이미지 데이터를 전송할 때 사용할 출력 형식을 지정합니다.
  - "auto"(기본값) : 이미지의 유형과 형식에 따라 압축 유형을 식별합니다.
  - "JPEG" : 사진 손실 압축
  - "PNG" : 다이어그램 무손실 압축
- `use_container_width`(bool, Keyword only) : 이미지의 너비를 부모(상위) 컨테이너의 너비로 설정할지 여부를 지정합니다. 만약, 이미지의 콘텐츠가 상위 컨테이너보다 넓으면 콘텐츠가 줄 바꿈됩니다.
  - True : 이미지의 너비를 부모(상위) 컨테이너의 너비와 일치하도록 설정합니다.
  - False(기본값) : 기본 이미지 너비, 콘텐츠에 맞게 이미지의 너비를 설정합니다.

<br>

**예시 1**

다음 예시는 `st.image`를 이용하여 이미지의 하단에 캡션을 나타내는 것을 보여줍니다.

```python
import streamlit as st

st.image("example.jpg", caption="image1")
```

```python
import streamlit as st
from PIL import Image

image = Image.open("example.jpg")

st.image(image, caption="image1")
```

![Untitled](/images/streamlit/chapter02/part03/Untitled.png)

<br>

**예시 2**

다음 예시는 `st.image`를 이용하여 `width`를 100으로 나타내는 예시입니다.

```python
import streamlit as st

st.image("example.jpg", caption="width=100", width=100)
```

```python
import streamlit as st
from PIL import Image

image = Image.open("example.jpg")

st.image(image, caption="width=100", width=100)
```

![Untitled](/images/streamlit/chapter02/part03/Untitled%201.png)

<br>

**예시 3**

다음 예시는 `st.image`를 이용하여 `width`가 200이고 `use_column_width`를 “auto”로 지정하여 원본 크기로 설정하지만 열의 너비를 초과하지 않는 경우를 보여줍니다. 또한 `width` 보다 우선시 설정되는 것을 보여줍니다.

```python
import streamlit as st

st.image("example.jpg", caption="example", width=200, use_container_width="auto")
```

```python
import streamlit as st
from PIL import Image

image = Image.open("example.jpg")

st.image(image, caption="example", width=200, use_container_width="auto")
```

![width=200](/images/streamlit/chapter02/part03/Untitled%202.png)

<br>

# st.logo

`st.logo`는 앱의 왼쪽 상단 모서리와 사이드바에 로고를 렌더링합니다. 한 페이지 내에서 `st.logo`를 여러 번 호출하면 마지막 호출에서 전달된 이미지를 렌더링합니다. 그렇기 때문에 일관된 결과를 얻으려면 페이지 스크립트 초반에 `st.logo`를 호출하는 것이 좋습니다.

```python
st.logo(image, *, size="medium", link=None, icon_image=None)
```

:::div{.callout}

로고 이미지는 주변에 빈 여백을 두지 않는 것을 권장드리며, 밝은 모드와 어두운 모드 모두에서 잘 작동하는 이미지를 선택하는 것이 좋습니다. [config.toml](https://docs.streamlit.io/develop/api-reference/configuration/config.toml)을 client.toolbarMode="minimal"으로 설정하여 사용자에게 설정 메뉴를 숨기는 것이 좋습니다.

:::

<br>

**매개변수**

- `image`(Anything supported by st.image(except list)) : 앱의 왼쪽 상단 모서리와 사이드바에 표시할 이미지입니다. 리스트를 제외한 `st.image`에서 지원하는 모든 유형이 가능합니다. `icon_image`도 제공하면 사이드바에만 이미지를 표시합니다. 사이드바에 맞도록 크기별로 설정된 최대 높이와 최대 너비에 맞게 이미지의 크기를 조정합니다.
- `size`("small", "medium", "large", Keyword only) : 앱의 왼쪽 상단 모서리와 사이드바에 표시되는 이미지의 크기입니다.
  - "small" : 최대 높이 20px
  - "medium"(기본값) : 최대 높이 24px
  - "large" : 최대 높이 32px
- `link`(str, None, Keyword only) : 사용자가 로고를 클릭할 때 열 외부 URL입니다. URL은 "http://" 또는 "https://"로 시작해야 하며, None(기본값)인 경우 로고에 하이퍼링크가 포함되지 않습니다.
- `icon_image`(Anything supported by st.image(except list), None, Keyword only) : 사이드바가 닫혔을 때 왼쪽 상단 모서리의 이미지를 대체하는 이미지로, 일반적으로 작은 이미지입니다. 리스트를 제외한 `st.image`에서 지원하는 모든 유형이 가능하며, None(기본값)인 경우 사이드바가 열려 있는지 닫혀 있는지에 관계없이 항상 왼쪽 상단 모서리에 이미지를 표시합니다. 그렇지 않으면 사이드바가 닫혀 있을 때 앱의 왼쪽 상단 모서리에 `icon_image`를 렌더링합니다.
  사이드바에 맞도록 크기별로 설정된 최대 높이와 최대 너비에 맞게 이미지의 크기를 조정합니다. 사이드바가 닫혀 있는 경우 최대 너비는 마지막으로 열었을 때의 너비가 유지됩니다.
  최상의 결과를 얻으려면 `icon_image`에 정사각형 이미지로 설정하거나 정사각형 이미지를 `image`에 전달하고 icon_image=None으로 설정합니다.

<br>

**예시 1**

다음 예시는 `st.logo`를 사용하여 앱에 로고를 생성합니다. 이때, `icon_image`를 함께 지정하면 `image`로 설정한 로고는 표시되지 않고 `icon_image`로 설정한 이미지만 출력됩니다. 또한 `link`를 사용하면 로고를 클릭했을 때 지정한 URL로 이동할 수 있도록 설정할 수 있습니다.

```python
import streamlit as st

LOGO_URL_LARGE = "./weniv-logo.png"
LOGO_URL_SMALL = "./weniv-symbol.svg"

st.logo(
    LOGO_URL_LARGE,
    link="https://weniv.co.kr",
    # icon_image=LOGO_URL_SMALL,
)
```

![icon_image 주석 처리 했을 때](/images/streamlit/chapter02/part03/스크린샷_2025-05-19_오후_3.02.59.png 'icon_image 주석 처리 했을 때')

![icon_image 적용할 때](/images/streamlit/chapter02/part03/스크린샷_2025-05-19_오후_3.02.17.png 'icon_image 적용할 때')

<br>

**예시 2**

다음 예시는 사이드바에는 더 넓은 형태의 로고 `image` 사용하고, 앱 상단에는 더 작은 아이콘 형태의 로고 `icon_image`를 사용합니다.

```python
import streamlit as st

LOGO_URL_LARGE = "./weniv-logo.png"
LOGO_URL_SMALL = "./weniv-symbol.svg"

st.logo(LOGO_URL_SMALL, icon_image=LOGO_URL_LARGE)
st.sidebar.markdown("MENU")
```

![사이드바 열렸을 때](/images/streamlit/chapter02/part03/스크린샷_2025-05-20_오후_2.13.28.png '사이드바 열렸을 때')

![사이드바 닫혔을 때](/images/streamlit/chapter02/part03/스크린샷_2025-05-20_오후_2.13.36.png '사이드바 닫혔을 때')

:::div{.callout}
`st.sidebar`는 Streamlit 레이아웃 함수로 버튼이나 메뉴 같은 요소를 앱의 왼쪽 사이드바에 넣을 수 있습니다.

:::

<br>

# **st.audio**

`st.audio`는 오디오 플레이어를 출력합니다.

```python
st.audio(data, format="audio/wav", start_time=0, *, sample_rate=None, end_time=None, loop=False, autoplay=False)
```

<br>

**매개변수**

- `data`(str, Path, bytes, BytesIO, numpy.ndarray, file) : 재생할 오디오 데이터입니다.
  - 오디오 파일명
  - 호스팅된 오디오 파일의 URL(문자열), 로컬 오디오 파일의 경로 중 하나입니다. 경로는 문자열 또는 Path 객체로, 경로는 작업 디렉터리(Streamlit 실행을 실행하는 위치)에 대한 절대 또는 상대 경로입니다.
  - 원시 오디오 데이터입니다. 원시 데이터 형식은 포맷을 통해 지정된 파일 형식과 일치하도록 필요한 모든 파일 헤더를 포함해야 합니다. 데이터가 NumPy 배열인 경우, 파형의 1D 배열이거나 모양(C, S)의 2D 배열이어야 하며, 여기서 C는 채널 수, S는 샘플 수입니다. 기본 채널 순서는 [http://msdn.microsoft.com/en-us/library/windows/hardware/dn653308(v=vs.85).aspx](<http://msdn.microsoft.com/en-us/library/windows/hardware/dn653308(v=vs.85).aspx>)에서 확인해주시길 바랍니다.
- `format`(str) : 오디오 파일의 MIME(Multipurpose Internet Mail Extensions) 타입입니다. MIME란 파일 변환을 의미하며, 인터넷에서 데이터를 정확하게 판별하기 위해 사용됩니다. 기본값은 “audio/wav”입니다. 오디오 파일의 데이터 타입을 명시적으로 지정해 줌으로써 Streamlit에서 해당 파일을 올바르게 읽어 수행 능력을 높일 수 있습니다.
  MIME 유형에 대한 자세한 내용은 [https://www.iana.org/assignments/media-types/media-types.xhtml](https://www.iana.org/assignments/media-types/media-types.xhtml) 을 참조해주시길 바랍니다.
- `start_time`(int, float, timedelta, str, None) : 오디오 재생의 시작 시간을 설정하는 매개변수로, 초 단위의 값을 입력합니다.
  - None(기본값) : 요소는 처음부터 재생됩니다.
  - 시간을 초 단위로 지정하는 int 또는 float입니다. float 값은 전체 초로 반내림됩니다.
  - Pandas의 [Timedelta](https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html) 생성자에서 지원하는 형식으로 시간을 지정하는 문자열입니다.
    ex) "2분", "20s", "1m14s" - [Python의 기본 제공 날짜/시간 라이브러리의 timedelta](https://docs.python.org/3/library/datetime.html#timedelta-objects) 객체
    `python
timedelta(seconds=70)
`
- `sample_rate`(int, None, Keyword only) : 오디오 데이터의 샘플 레이트(초당 샘플 수)입니다. 데이터가 NumPy 배열인 경우에만 필요합니다.
- `end_time`(int, float, timedelta, str, None, Keyword only) : 요소의 재생을 중지할 시간입니다.
  - None(기본값) : 요소가 끝까지 재생됩니다.
  - 시간을 초 단위로 지정하는 int 또는 float입니다. float 값은 반올림됩니다.
  - Pandas의 [Timedelta](https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html) 생성자에서 지원하는 형식으로 시간을 지정하는 문자열입니다.
    ex) "2분", "20s", "1m14s" - [Python의 기본 제공 날짜/시간 라이브러리의 timedelta](https://docs.python.org/3/library/datetime.html#timedelta-objects) 객체
    `python
timedelta(seconds=70)
`
- `loop`(boo, Keyword onlyl) : 오디오를 반복 재생할지 여부입니다.
- `autoplay`(bool, Keyword only) : 오디오 파일 재생을 자동으로 시작할지 여부입니다. 기본값은 False입니다. 사용자가 어딘가를 클릭하여 페이지와 상호 작용하지 않은 경우 브라우저는 오디오 파일을 자동 재생하지 않습니다.

<br>

**예시 1**

다음 예시는 오디오 파일을 불러와서 `st.audio`를 사용하여 보여주는 예시입니다. 이때, 로컬 파일의 문자열 경로와 형식을 지정합니다.

```python
import streamlit as st

st.audio("Bubblegum Code-2.mp3", format="audio/mpeg", loop=True)
```

![Untitled](/images/streamlit/chapter02/part03/Untitled%203.png)

<br>

**예시 2**

다음 예시는 오디오 파일을 불러와서 `st.audio`를 사용하여 보여주는 예시입니다. open 함수를 사용해 오디오 파일을 열어줍니다. “rb”는 “read binary”의 약자입니다. 오디오 파일은 대개 바이너리 형식으로 저장되기 때문에 이를 읽기 위해서 “rb” 모드를 설정하여 audio_bytes 변수에 저장합니다. “rb” 모드를 설정하지 않으면 에러 메시지가 나타납니다. read 함수를 통해 오디오 파일을 읽어오고 `st.audio`를 사용하여 보여줍니다.

```python
import streamlit as st

audio_file = open("Bubblegum Code-2.mp3", "rb")
audio_bytes = audio_file.read()

st.audio(audio_bytes, format="audio/mp3", start_time=5)
```

![Untitled](/images/streamlit/chapter02/part03/Untitled%203.png)

<br>

**예시 3**

다음 예시는 Numpy.ndarray 객체를 이용해 소리의 사인 파(sine wave)를 만들어 재생하는 예시입니다. 사인 파는 소리가 가지는 가장 간단한 파형 중 하나입니다. 재생할 음파의 초당 샘플 수, 음이 지속될 시간, 표현할 음계를 지정합니다. 위 코드의 440은 440Hz를 뜻합니다. 440Hz는 음계 ‘라’의 헤르츠 숫자입니다. Numpy 라이브러리를 활용해 초당 샘플 수 \* 초 배열을 생성합니다. 생성한 배열로 440 헤르츠의 사인 파를 만듭니다. `st.audio`를 활용해 앞서 만들어 준 사인파와, Numpy 배열에만 사용되는 sample_rate 파라미터의 값을 넣어줍니다.

```python
import streamlit as st
import numpy as np

sample_rate = 44100  # 44100 초당 샘플수
seconds = 2  # 2초 동안 음이 지속됩니다.
frequency_la = 440  # 재생할 음파를 나타냅니다.

t = np.linspace(0, seconds, seconds * sample_rate, False)
note_la = np.sin(frequency_la * t * 2 * np.pi) #440 헤르쯔의 사인파를 만듭니다.

st.audio(note_la, sample_rate=sample_rate)
```

![Untitled](/images/streamlit/chapter02/part03/Untitled%204.png)

<br>

# **st.video**

`st.video`는 동영상 플레이어를 출력합니다.

```python
st.video(data, format="video/mp4", start_time=0, *, subtitles=None, end_time=None, loop=False, autoplay=False, muted=False)
```

<br>

**매개변수**

- `data`(str, Path, bytes, io.BytesIO, numpy.ndarray, file) : 표시할 동영상 데이터로 동영상 파일명이나 동영상 파일을 가리키는 URL입니다.
  - YouTube URL을 포함하여 호스팅된 비디오 파일의 URL(문자열)을 넣을 수 있습니다.
  - 로컬 비디오 파일의 경로로, 경로는 문자열 또는 Path 객체, 작업 디렉토리(Streamlit 실행을 실행하는 위치)에 대한 절대 또는 상대 경로일 수 있습니다.
  - 원시 비디오 데이터로 원시 데이터 형식에는 포맷을 통해 지정된 파일 형식과 일치하는 데 필요한 모든 파일 헤더가 포함되어야 합니다.
- `format`(str) : 동영상 파일의 MIME(Multipurpose Internet Mail Extensions) 타입입니다. MIME란 파일 변환을 의미하며, 인터넷에서 데이터를 정확하게 판별하기 위해 사용됩니다. 기본값은 ‘video/mp4’입니다. 동영상 파일의 데이터 타입을 명시적으로 지정해 줌으로써 Streamlit에서 해당 파일을 올바르게 읽어 수행 능력을 높일 수 있습니다.
  - MIME 유형에 대한 자세한 내용은 [https://www.iana.org/assignments/media-types/media-types.xhtml](https://www.iana.org/assignments/media-types/media-types.xhtml) 을 참조해주시길 바랍니다.
- `start_time`(int, float, timedelta, str, None) : 영상 재생의 시작 시간을 설정하는 매개변수로, 초 단위의 값을 입력합니다.
  - None(기본값) : 요소가 처음부터 재생됩니다.
  - 시간을 초 단위로 지정하는 정숫값 또는 부동 소수점. 부동 소수점 값은 전체 초로 반내림됩니다.
  - Pandas의 Timedelta 생성자에서 지원하는 형식으로 시간을 지정하는 문자열입니다.
    ex) "2분", "20초" 또는 "1m14초"
  - Python의 기본 제공 날짜/시간 라이브러리의 timedelta 객체
    ```python
     timedelta(seconds=70)
    ```
- `subtitles`(str, bytes, Path, io.BytesIO, dict, Keyword only) : 여러 입력 유형을 지원하는 비디오의 자막 데이터(선택 사항)입니다.
  - None(기본값) : 자막이 없습니다.
  - 문자열, 바이트 또는 경로로 .vtt 또는 .srt 형식의 자막 파일의 파일 경로 또는 이러한 형식을 따르는 자막의 원시 콘텐츠입니다. 경로는 작업 디렉터리(Streamlit 실행을 실행하는 위치)에 대한 절대 또는 상대 경로여야 합니다. 또한, 원시 콘텐츠를 제공하는 경우 문자열은 WebVTT 또는 SRT 형식 사양을 준수해야 합니다.
  - io.BytesIO : 유효한 .vtt 또는 .srt 형식의 자막 데이터가 포함된 BytesIO 스트림입니다.
  - dict : 여러 자막 트랙을 사용할 수 있도록 .vtt 또는 .srt 형식의 레이블과 파일 경로 또는 원시 자막 콘텐츠 쌍입니다. 레이블은 동영상 플레이어에 표시됩니다.
    ex) {"영어": "경로/투/영어.vtt", "프랑스어": "경로/to/french.srt"}
    자막이 제공되면 기본적으로 자막이 표시됩니다. 트랙이 여러 개인 경우 기본적으로 첫 번째 트랙이 표시됩니다. 기본적으로 자막을 표시하지 않으려면 딕셔너리의 첫 번째 쌍에 있는 값에 빈 문자열을 사용하면 됩니다. 단, YouTube 동영상에는 지원되지 않습니다.
    ex) {"None": "", "영어": "path/to/english.vtt"}
- `end_time`(int, float, timedelta, str, None, Keyword only) : 영상 재생의 종료 시간을 설정하는 매개변수로, 초 단위의 값을 입력합니다. 요소의 재생을 중지해야 하는 시간입니다.
  - None(기본값) : 요소가 끝까지 재생됩니다.
  - 시간을 초 단위로 지정하는 정수값 또는 부동 소수점. 부동 소수점 값은 전체 초로 반내림됩니다.
  - Pandas의 Timedelta 생성자에서 지원하는 형식으로 시간을 지정하는 문자열
    ex) "2분", "20초" 또는 "1m14초"
  - Python의 기본 제공 날짜/시간 라이브러리의 timedelta 객체
    ```python
     timedelta(seconds=70)
    ```
- `loop`(bool, Keyword only) : 동영상을 반복 재생할지 여부입니다.
- `autoplay`(bool, Keyword only) : 동영상 재생을 자동으로 시작할지 여부입니다. 기본값은 False입니다. 사용자가 페이지 어딘가를 클릭하여 페이지와 상호 작용하지 않은 경우 브라우저는 음소거되지 않은 동영상을 자동 재생하지 않습니다. 사용자 상호 작용 없이 자동 재생을 사용하려면 muted=True으로 설정해야 합니다.
- `muted`(bool, Keyword only) : 오디오를 음소거한 상태로 동영상을 재생할지 여부입니다. 기본값은 False입니다. 사용자 상호 작용 없이 자동 재생을 사용하려면 autoplay = True와 함께 사용합니다.

<br>

**예시 1**

다음 예시는 동영상 파일을 불러와서 `st.video`를 사용하여 보여주는 예시입니다. open 함수를 사용해 동영상 파일을 열고 “rb” 모드를 설정하여 video_bytes 변수에 저장합니다. 그리고 read 함수를 통해 동영상 파일을 읽어오고 `st.video`를 사용하여 보여줍니다.

```python
import streamlit as st

# 동영상 파일을 로컬 경로에서 재생하는 예시
video_file = open("example.mp4", "rb")
video_bytes = video_file.read()

st.video(video_bytes)
```

![스크린샷 2025-05-19 오후 4.53.17.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-19_오후_4.53.17.png)

<br>

**예시 2**

다음 예시는 동영상 파일을 URL로 불러와서 `st.video`를 사용하여 보여주는 예시입니다.

```python
import streamlit as st

# 동영상 파일을 URL에서 재생하는 예시
video_url = "https://youtu.be/G93eK_ZUrwc?si=fP0n8seX4CGxDoQ-"

st.video(video_url)
```

![스크린샷 2025-05-19 오후 4.55.06.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-19_오후_4.55.06.png)

<br>

**예시 3**

다음 예시는 동영상 파일을 불러와서 `st.video`에 자막을 표시하여보여주는 예시입니다. VTT 파일이 앱과 같은 디렉토리에 있는 경우 아래 코드와 같이 자막을 추가할 수 있습니다.

```python
WEBVTT

0:00:01.000 --> 0:00:02.000
Look!

0:00:03.000 --> 0:00:05.000
Look at the pretty clouds!
```

```python
import streamlit as st

st.video('example.mp4', subtitles="subtitles.vtt")
```

자막을 포함하면 자막이 기본적으로 켜져 있습니다. 시청자는 일반적으로 동영상의 오른쪽 하단에 있는 브라우저의 기본 동영상 제어 메뉴에서 자막(또는 캡션)을 끌 수 있습니다.

![스크린샷 2025-05-19 오후 5.09.03.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-19_오후_5.09.03.png)

:::div{.callout}

MP4V 코덱은 브라우저에서 널리 지원되지 않으므로 일부 동영상은 MP4V(OpenCV의 내보내기 옵션)를 사용하여 인코딩된 경우 표시되지 않을 수 있습니다. 동영상을 H.264로 변환하면 Streamlit에 동영상이 표시될 수 있습니다. 자막 지원 관련 추가 예시는 [동영상 자막 기능 데모](https://doc-video-subtitle-inputs.streamlit.app/)를 참고해주시길 바랍니다.

:::

<br>

# st.audio_input

`st.audio_input`는 사용자의 마이크에서 오디오 녹음하여 반환합니다.

```python
st.audio_input(label, *, key=None, help=None, on_change=None, args=None, kwargs=None, disabled=False, label_visibility="visible")
```

<br>

**매개변수**

- `label`(str) : 사용자에게 오디오 입력 위젯이 어떤 용도로 사용되는지 간략히 설명하는 레이블입니다. 일부 마크다운을 지원합니다. 이미지는 아이콘처럼 표시되며 최대 높이는 글꼴 높이와 같습니다. 지원되지 않는 마크다운 요소는 래핑이 해제되어 해당 하위 요소(텍스트 콘텐츠)만 렌더링됩니다. 지원되지 않는 요소는 백슬래시 이스케이프를 사용하여 리터럴 문자로 표시합니다. ex) 1\. 정렬된 목록이 아님
  접근성을 위해 빈 레이블을 설정해서는 안 되지만, 필요한 경우 `label_visibility`를 사용하여 숨길 수 있습니다. 향후에는 예외를 발생시켜 빈 레이블을 허용하지 않을 수 있습니다.
- `key`(str, int, Keyword only) : 위젯의 고유 키로 사용할 문자열 또는 정수로 요소에 ID를 부여하는데 사용합니다. `key`가 생략된 경우, 위젯의 내용을 기반으로 키가 생성됩니다. `key`는 위젯의 상태를 식별하고 추적하기 때문에 동일한 유형의 여러 위젯은 동일한 키를 공유할 수 없습니다. 만약, 동일 위젯이 동일 `label`을 가지고 버튼을 생성하였을 때, 동일한 키를 공유할 수 없어 DuplicateWidgetID 에러가 발생합니다.
- `help`(str, None, Keyword only) : 사용자에게 오디오 입력 위젯 옆에 도움말 텍스트를 제공하기 위해 사용합니다. 지정한 도움말 오디오 입력 위젯 레이블 옆에 "?" 아이콘으로 표시되며, 마우스를 가져다 대면 툴팁으로 표시됩니다. label_visibility="visible"일 때만 툴팁을 표시하며, 설명에는 마크다운을 사용할 수 있습니다. None(기본값)이면 툴팁이 표시되지 않습니다.
- `on_change`(callable, Keyword only) : 오디오 입력값이 변경될 때 호출되는 선택적 콜백 함수입니다.
- `args`(tuple, Keyword only) : 콜백에 전달할 선택적 인수 튜플입니다.
- `kwargs`(dict, Keyword only) : 콜백에 전달할 선택적 `kwargs` 딕셔너리입니다.
- `disabled`(bool, Keyword only) : 오디오 입력을 활성화하거나 비활성화할 수 있습니다.
  - False(기본값) : 오디오 입력 활성화
  - True : 오디오 입력 비활성화, 비활성화된 위젯은 사용자가 어떠한 조작을 입력할 수 없습니다.
- `label_visibility`("visible", "hidden", "collapsed", Keyword only) : 레이블의 표시 여부입니다.
  - "visible"(기본값) : 레이블을 필드 위에 표시합니다. 필드는 위젯의 값이 입력되는 공간을 의미합니다.
  - "hidden" : 레이블은 표시되지 않지만, 위젯 위에 빈 공간(공백)을 표시하여 위젯을 다른 위젯과 정렬하는 데 도움을 줍니다.(label=""와 동일)
  - "collapsed" : 레이블과 공백이 모두 제거됩니다. 기본값은 `label`을 보여 줍니다.

<br>

**반환값**

- None, UploadedFile : UploadedFile 클래스는 BytesIO의 서브 클래스이므로 "파일과 유사"합니다. 즉, 파일이 필요한 곳이면 어디든 클래스의 인스턴스를 전달할 수 있습니다. 오디오 데이터의 MIME 유형은 audio/wav입니다. 반환된 업로딩된 파일은 server.maxUploadSize에 구성된 크기 제한의 적용을 받습니다. 대용량 사운드 파일이 예상되는 경우 구성 옵션을 적절히 업데이트하시길 바랍니다.

<br>

**예시 1**

다음 예시는 사용자가 음성 메시지를 직접 녹음할 수 있도록 입력을 받고, 녹음된 음성을 재생할 수 있습니다.

```python
import streamlit as st

audio_value = st.audio_input("음성 메시지를 녹음합니다.")

if audio_value:
    st.audio(audio_value)
```

![스크린샷 2025-05-26 오후 4.26.32.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.26.32.png)

![녹음 중](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.26.45.png '녹음 중')

![녹음 종료](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.26.54.png '녹음 종료')

<br>

# st.camera_input

`st.camera_input`은 사용자의 웹 카메라에 접근하여 실시간 카메라 화면을 캡처하여 사진을 반환합니다. 캡처한 이미지 파일의 내용을 읽거나 처리하거나 디스크에 저장하는 등의 작업을 할 수 있습니다. 다양한 데이터 처리 라이브러리를 통해 출력된 결과물을 활용할 수 있습니다. 각 라이브러리에 따라 웹 디바이스에서 캡처된 이미지의 Type과 Class가 변환되어 출력됩니다.

```python
st.camera_input(label, key=None, help=None, on_change=None, args=None,
                kwargs=None, *, disabled=False, label_visibility="visible")
```

:::div{.callout}
브라우저에서 카메라 기능 허용 후 사용자의 웹 카메라에 접근하여 촬영할 수 있습니다.

:::

<br>

**매개변수**

- `label`(str) : 사용자에게 카메라 촬영 위젯이 어떤 용도로 사용되는지 간략히 설명하는 레이블입니다. 일부 마크다운을 지원합니다. 이미지는 아이콘처럼 표시되며 최대 높이는 글꼴 높이와 같습니다. 지원되지 않는 마크다운 요소는 래핑이 해제되어 해당 하위 요소(텍스트 콘텐츠)만 렌더링됩니다. 지원되지 않는 요소는 백슬래시 이스케이프를 사용하여 리터럴 문자로 표시합니다. ex) 1\. 정렬된 목록이 아님
  접근성을 위해 빈 레이블을 설정해서는 안 되지만, 필요한 경우 `label_visibility`를 사용하여 숨길 수 있습니다. 향후에는 예외를 발생시켜 빈 레이블을 허용하지 않을 수 있습니다.
- `key`(str, int) : 위젯의 고유 키로 사용할 문자열 또는 정수로 요소에 ID를 부여하는데 사용합니다. `key`가 생략된 경우, 위젯의 내용을 기반으로 키가 생성됩니다. `key`는 위젯의 상태를 식별하고 추적하기 때문에 동일한 유형의 여러 위젯은 동일한 키를 공유할 수 없습니다. 만약, 동일 위젯이 동일 `label`을 가지고 버튼을 생성하였을 때, 동일한 키를 공유할 수 없어 DuplicateWidgetID 에러가 발생합니다.
- `help`(str, None) : 사용자에게 카메라 촬영 위젯 옆에 도움말 텍스트를 제공하기 위해 사용합니다. 지정한 도움말 카메라 촬영 위젯 레이블 옆에 "?" 아이콘으로 표시되며, 마우스를 가져다 대면 툴팁으로 표시됩니다. label_visibility="visible"일 때만 툴팁을 표시하며, 설명에는 마크다운을 사용할 수 있습니다. None(기본값)이면 툴팁이 표시되지 않습니다.
- `on_change`(callable) : 카메라 입력값이 변경될 때 호출되는 선택적 콜백 함수입니다.
- `args`(tuple) : 콜백에 전달할 선택적 인수 튜플입니다.
- `kwargs`(dict) : 콜백에 전달할 선택적 `kwargs` 딕셔너리입니다.
- `disabled`(bool, Keyword only) : 카메라 입력을 활성화하거나 비활성화할 수 있습니다.
  - False(기본값) : 카메라 입력 활성화
  - True : 카메라 입력 비활성화, 비활성화된 위젯은 사용자가 어떠한 조작을 입력할 수 없습니다.
- `label_visibility`("visible", "hidden", "collapsed", Keyword only) : 레이블의 표시 여부입니다.
  - "visible"(기본값) : 레이블을 필드 위에 표시합니다. 필드는 위젯의 값이 입력되는 공간을 의미합니다.
  - "hidden" : 레이블은 표시되지 않지만, 위젯 위에 빈 공간(공백)을 표시하여 위젯을 다른 위젯과 정렬하는 데 도움을 줍니다.(label=""와 동일)
  - "collapsed" : 레이블과 공백이 모두 제거됩니다. 기본값은 `label`을 보여 줍니다.

<br>

**반환값**

- None, UploadedFile : UploadedFile 클래스는 BytesIO의 서브(하위) 클래스이므로 "파일과 유사"합니다. 즉, 파일이 필요한 모든 곳에 클래스의 인스턴스를 전달할 수 있습니다.

<br>

**예시 1**

다음 예시는 “Take photo” 버튼을 클릭하면 사용자의 웹 카메라에서 이미지를 캡처합니다. 캡처된 이미지는 하단에 표시됩니다. 마우스 우클릭을 통해 이미지를 사용자의 드라이브에 저장할 수 있습니다.

```python
import streamlit as st

picture = st.camera_input("사진을 찍을 수 있습니다.")

if picture:
    st.image(picture)
```

![사진 찍기 전](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.38.53.png '사진 찍기 전')
![사진 찍은 후](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.41.00.png '사진 찍은 후')

<br>

**예시 2**

다음 예시는 `disabled`를 True로 설정하여 카메라 촬영 위젯을 비활성화 시키거나, False로 설정하여 활성화시킬 수 있습니다.

```python
import streamlit as st

picture = st.camera_input("사진을 찍을 수 있습니다.", disabled=True, key=1)
picture = st.camera_input("사진을 찍을 수 있습니다.", disabled=False, key=2)

if picture:
    st.image(picture)
```

![스크린샷 2025-05-26 오후 4.50.49.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.50.49.png)

<br>

**예시 3**

다음 예시는 이미지 파일 버퍼 데이터를 바이트로 저장합니다. 데이터를 전송할 때, 데이터를 작은 블록 단위로 나눠 전송합니다. 버퍼란 작은 단위로 나눠진 데이터를 임시로 저장하는 메모리 공간입니다. 사용자의 웹 디바이스에서 캡처한 이미지의 데이터 타입을 출력합니다. UploadedFile 객체에서 getvalue() 메서드를 사용하여 바이트 데이터로 이미지를 읽어옵니다.

```python
import streamlit as st

file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if file_buffer is not None:
    bytes_data = file_buffer.getvalue()
    st.write(type(bytes_data)) # bytes_data의 타입 확인
```

![스크린샷 2025-05-26 오후 4.41.45.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.41.45.png)

<br>

**예시 4**

Pillow, NumPy, OpenCV, TensorFlow, torchvision, PyTorch 등 널리 사용되는 이미지 및 데이터 처리 라이브러리를 활용하여 사용자의 웹 디바이스에서 캡처한 이미지를 사용할 수 있습니다.

다음 예시는 Pillow(PIL)는 이미지 파일을 조작하고 저장하는 데 사용되며 이미지 처리, 크기 조정 등에 활용합니다. Pillow(PIL) 라이브러리의 Image 모듈을 사용해서 이미지를 불러온 뒤, Numpy 배열로 변환하여 출력합니다. 먼저, Pillow와 NumPy를 설치합니다.

```bash
pip install pillow numpy
```

```python
import streamlit as st
from PIL import Image
import numpy as np

st.header("camera_input()")
st.subheader("PIL, Numpy 라이브러리")

file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if file_buffer is not None:
    image_pil = Image.open(file_buffer)

    # To convert PIL Image to numpy array:
    image_array = np.array(image_pil)

    # image_array의 타입 출력
    # <class "numpy.ndarray">
    st.write(type(image_array))

    # image_array의 shape 출력
    # (height, width, channels)
    st.write(image_array.shape)
```

![스크린샷 2025-05-26 오후 4.44.55.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.44.55.png)

![스크린샷 2025-05-26 오후 4.45.19.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_4.45.19.png)

<br>

다음 예시는 사용자가 웹캠으로 사진을 촬영하면, 그 이미지 데이터를 OpenCV의 imdecode 함수를 사용해 메모리 버퍼에서 읽어 들여 Numpy 배열로 변환하는 과정을 보여줍니다. 변환된 이미지는 OpenCV에서 처리 가능한 형식이며, cv2_img.shape로 이미지의 크기(높이, 너비, 채널 수)를 확인할 수 있습니다.

이 과정에서 OpenCV는 이미지 디코딩과 조작에, NumPy는 이미지 데이터를 배열 형태로 다루는 데 사용됩니다. 먼저, OpenCV와 NumPy 라이브러리를 설치해야 합니다.

```python
import streamlit as st
import cv2
import numpy as np

st.header("camera_input()")
st.subheader("OpenCV, Numpy 라이브러리")

img_file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if img_file_buffer is not None:
    # To read image file buffer with OpenCV:
    bytes_data = img_file_buffer.getvalue()
    cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

    # cv2_img 타입 출력
    # <class 'numpy.ndarray'>
    st.write(type(cv2_img))

    # cv2_img의 shape 출력
    # (height, width, channels)
    st.write(cv2_img.shape)
```

![스크린샷 2025-05-26 오후 5.19.18.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.19.18.png)

![스크린샷 2025-05-26 오후 5.20.34.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.20.34.png)

<br>

다음 예시는 사용자가 웹캠으로 촬영한 이미지를 TensorFlow의 tf.io.decode_image 함수로 메모리 버퍼에서 3채널(컬러) 이미지 텐서로 디코딩하는 과정을 보여줍니다. 결과는 tf.Tensor 형태이며, 이미지의 높이, 너비, 채널 수를 포함한 3차원 텐서입니다. TensorFlow는 이미지 처리, 변환, 신경망 입력 등 다양한 작업에 활용되며, 이 예제는 이미지 읽기와 텐서 변환에 중점을 둡니다. 먼저 TensorFlow를 설치한 후, 이미지 파일 버퍼를 3차원 uint8 텐서로 읽어옵니다.

```python
import streamlit as st
import tensorflow as tf

st.header("camera_input()")
st.subheader("Tensorflow 라이브러리")

img_file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if img_file_buffer is not None:
    # To read image file buffer as a 3D uint8 tensor with TensorFlow:
    bytes_data = img_file_buffer.getvalue()
    img_tensor = tf.io.decode_image(bytes_data, channels=3)

    # img_tensor 타입 출력
    # <class 'tensorflow.python.framework.ops.EagerTensor'>
    st.write(type(img_tensor))

    # img_tensor의 shape 출력
    # (height, width, channels)
    st.write(img_tensor.shape)
```

![스크린샷 2025-05-26 오후 5.26.25.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.26.25.png)

![스크린샷 2025-05-26 오후 5.26.42.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.26.42.png)

<br>

다음 예시는 사용자가 웹캠으로 촬영한 이미지를 torchvision.io.decode_image 함수를 사용해 메모리 버퍼에서 3채널(컬러) 이미지 PyTorch 텐서로 디코딩하는 과정을 보여줍니다.

img_file_buffer.getvalue()를 통해 이미지의 바이트 데이터를 가져온 후, torch.frombuffer를 사용해 uint8 형식의 1차원 텐서로 변환합니다. 이후 torchvision.io.decode_image를 사용해 이 데이터를 [채널, 높이, 너비] 형태의 3차원 이미지 텐서로 디코딩합니다. 결과는 torch.Tensor 객체이며, PyTorch에서 이미지 처리나 모델 입력 등 다양한 딥러닝 작업에 활용할 수 있습니다. 참고로, torchvision.io.decode_image는 PNG, JPEG, BMP 형식의 이미지를 지원합니다.

먼저 torchvision 라이브러리를 설치한 후, 이미지 파일 버퍼를 3차원 uint8 텐서로 불러올 수 있습니다.

:::div{.callout}

torch.ops.image.decode_image는 PyTorch 설치 환경에 따라 다르게 작동할 수 있으며, 일반적으로는 torchvision.io.read_image 사용이 권장됩니다.

:::

```python
import streamlit as st
import torch
import torchvision

st.header("camera_input()")
st.subheader("Torchvision 라이브러리")

img_file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if img_file_buffer is not None:
    # To read image file buffer as a 3D uint8 tensor with `torchvision.io`:
    bytes_data = img_file_buffer.getvalue()
    torch_img = torchvision.io.decode_image(
        torch.frombuffer(bytes_data, dtype=torch.uint8)
    )

    # torch_img 타입 출력
    # <class 'torch.Tensor'>
    st.write(type(torch_img))

    # torch_img의 shape 출력
    # torch.Size([channels, height, width])
    st.write(torch_img.shape)
```

![스크린샷 2025-05-26 오후 5.48.17.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.48.17.png)

![스크린샷 2025-05-26 오후 5.48.37.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.48.37.png)

<br>

다음 예시는 PyTorch는 이미지 데이터를 텐서로 변환하고 딥러닝 모델에 입력하는 데 활용되며, NumPy는 바이트 데이터를 배열 형태로 변환하는 데 사용됩니다. PyTorch와 NumPy 라이브러리를 활용해 이미지 파일 버퍼를 3차원 텐서로 변환한 뒤, 해당 텐서의 정보를 출력합니다. 먼저 PyTorch와 NumPy를 설치합니다.

PyTorch로 이미지 파일 버퍼를 3차원 uint8 텐서로 읽습니다.

```python
import streamlit as st
import torch
import numpy as np

st.header("camera_input()")
st.subheader("PyTorch 라이브러리")

img_file_buffer = st.camera_input("사진을 찍을 수 있습니다.")

if img_file_buffer is not None:
    # To read image file buffer as a 3D uint8 tensor with PyTorch:
    bytes_data = img_file_buffer.getvalue()
    torch_img = torch.ops.image.decode_image(
        torch.from_numpy(np.frombuffer(bytes_data, np.uint8)), 3
    )

    # torch_img 타입 출력
    # <class 'torch.Tensor'>
    st.write(type(torch_img))

    # torch_img의 shape 출력
    # torch.Size([channels, height, width])
    st.write(torch_img.shape)
```

![스크린샷 2025-05-26 오후 5.49.56.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.49.56.png)

![스크린샷 2025-05-26 오후 5.49.28.png](/images/streamlit/chapter02/part03/스크린샷_2025-05-26_오후_5.49.28.png)

<br>

# Third-party components

- https://github.com/andfanilo/streamlit-drawable-canvas
- https://github.com/fcakyon/streamlit-image-comparison
- https://github.com/turner-anderson/streamlit-cropper
- https://github.com/blackary/streamlit-image-coordinates
- https://github.com/andfanilo/streamlit-lottie
- https://github.com/whitphx/streamlit-webrtc
- https://github.com/blackary/streamlit-camera-input-live
